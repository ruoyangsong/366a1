#!/usr/bin/env python

"""
  Author: Adam White, Mohammad M. Ajallooeian
  Purpose: for use of Reinforcement learning course University of Alberta Fall 2017
 
  env *ignores* actions: rewards are all random
"""

from utils import rand_norm, rand_in_range, rand_un
import numpy as np

this_reward_observation = (None, None, None) # this_reward_observation: (floating point, NumPy array, Boolean)


q=[0,0,0,0,0,0,0,0,0,0]   
#the list to store the real reward generated by the bandit each step
real_reward = [0,0,0,0,0,0,0,0,0,0]
    
     
def env_init():
    global this_reward_observation,q
    local_observation = np.zeros(0) # An empty NumPy array

    this_reward_observation = (0.0, local_observation, False)
    
    #set up q*(a)
    for i in range(0,10):
        q[i]=rand_norm(0.0, 1.0) 


def env_start(): # returns NumPy array
    return this_reward_observation[1]

def env_step(this_action): # returns (floating point, NumPy array, Boolean), this_action: NumPy array
    
    global this_reward_observation,real_reward,q
    
    # rewards drawn from (q(At), 1) Gaussian
    for i in range(10):
        real_reward[i] = rand_norm(q[i], 1)
    
    the_reward = real_reward[this_action]
    
    #print "the reward for action %d is %f, optimal is %d,optimal value is %f"%(int(this_action),the_reward,max(enumerate(real_reward),key=lambda x: x[1])[0],real_reward[max(enumerate(real_reward),key=lambda x: x[1])[0]])

    this_reward_observation = (the_reward, this_reward_observation[1], False)

    return this_reward_observation

def env_cleanup():
    #
    return

def env_message(inMessage): # returns string, inMessage: string
    global q
    if inMessage == "what is your name?":
        return "my name is skeleton_environment!"
    
    elif inMessage == "get optimal action":
            #get which action has the largest reward
            return max(enumerate(q),key=lambda x: x[1])[0]    
    
    # else
    return "I don't know how to respond to your message"
